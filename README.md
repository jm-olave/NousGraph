# Health Project - Medical Text Classification

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema de clasificaciÃ³n multi-etiqueta de textos mÃ©dicos utilizando PubMedBERT, un modelo basado en BERT especÃ­ficamente entrenado en literatura mÃ©dica. El sistema es capaz de clasificar artÃ­culos mÃ©dicos en cuatro categorÃ­as principales:

- **Neurological** (NeurolÃ³gico)
- **Cardiovascular** (Cardiovascular)
- **Hepatorenal** (Hepatorrenal)
- **Oncological** (OncolÃ³gico)

## ğŸ¯ Objetivos

- Clasificar automÃ¡ticamente documentos mÃ©dicos en mÃºltiples categorÃ­as simultÃ¡neamente
- Manejar el desbalance de clases tÃ­pico en datasets mÃ©dicos
- Optimizar el rendimiento para casos multi-etiqueta raros
- Proporcionar predicciones con niveles de confianza

## ğŸ—ï¸ Estructura del Proyecto

```
health_project/
â”œâ”€â”€ README.md                           # Este archivo
â”œâ”€â”€ requirements.txt                    # Dependencias del proyecto
â”œâ”€â”€ main.py                            # Script principal de ejecuciÃ³n
â”œâ”€â”€ challenge_data-18-ago.csv          # Dataset de entrenamiento
â”œâ”€â”€ DataAnalysis.ipynb                 # AnÃ¡lisis exploratorio de datos
â”œâ”€â”€ last_final.ipynb                  # Notebook final con entrenamiento completo
â”œâ”€â”€ confusion_matrix_analysis.py       # AnÃ¡lisis de matriz de confusiÃ³n
â”œâ”€â”€ simple_confusion_matrix.py         # Matriz de confusiÃ³n simplificada
â”œâ”€â”€ src/                               # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                        # FunciÃ³n principal de entrenamiento
â”‚   â”œâ”€â”€ model_utils.py                 # Utilidades del modelo
â”‚   â”œâ”€â”€ data_processing.py             # Procesamiento de datos
â”‚   â”œâ”€â”€ training.py                    # Clases de entrenamiento
â”‚   â”œâ”€â”€ prediction.py                  # Funciones de predicciÃ³n
â”‚   â”œâ”€â”€ augmentation.py                # TÃ©cnicas de data augmentation
â”‚   â””â”€â”€ pubmedbert-medical-v6/         # Modelo entrenado
â””â”€â”€ wandb/                             # Logs de experimentos
```

## ğŸ”§ InstalaciÃ³n

### Requisitos
- Python 3.8+
- CUDA (para entrenamiento con GPU)

### ConfiguraciÃ³n del entorno
```bash
# Clonar el repositorio
git clone <repository-url>
cd health_project

# Instalar dependencias
pip install -r requirements.txt
```

### Dependencias principales
- `torch` - PyTorch para deep learning
- `transformers` - Biblioteca de Hugging Face para modelos pre-entrenados
- `scikit-learn` - MÃ©tricas y divisiÃ³n de datos
- `pandas` - ManipulaciÃ³n de datos
- `numpy` - Operaciones numÃ©ricas
- `wandb` - Seguimiento de experimentos
- `seaborn`, `matplotlib` - VisualizaciÃ³n

## ğŸ“Š Dataset

El dataset `challenge_data-18-ago.csv` contiene **3,565 artÃ­culos mÃ©dicos** con:
- **title**: TÃ­tulo del artÃ­culo
- **abstract**: Resumen del artÃ­culo
- **group**: CategorÃ­as mÃ©dicas (separadas por "|")

### DistribuciÃ³n de clases
```
neurological:                    1,058 (29.7%)
cardiovascular:                    645 (18.1%)
hepatorenal:                       533 (15.0%)
neurological|cardiovascular:       308 (8.6%)
oncological:                       237 (6.6%)
neurological|hepatorenal:          202 (5.7%)
cardiovascular|hepatorenal:        190 (5.3%)
neurological|oncological:          143 (4.0%)
...y mÃ¡s combinaciones
```

## ğŸš€ Uso

### Entrenamiento del modelo
```bash
python main.py
```

### Uso desde cÃ³digo Python
```python
from src.main import train_optimized_medical_classifier
from src.prediction import predict_medical_categories

# Entrenar modelo
trainer, metrics = train_optimized_medical_classifier("challenge_data-18-ago.csv")

# Hacer predicciones
text = "Patient developed cardiotoxicity after chemotherapy treatment..."
predictions = predict_medical_categories(text)

for pred in predictions:
    if pred['predicted']:
        print(f"{pred['category']}: {pred['probability']:.3f}")
```

## ğŸ§  Arquitectura del Modelo

### Modelo Base
- **PubMedBERT**: `microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext`
- **Tipo**: ClasificaciÃ³n multi-etiqueta
- **Salida**: 4 neuronas con activaciÃ³n sigmoidal

### Optimizaciones implementadas

1. **Manejo de desbalance de clases**:
   - Pesos de clase calculados automÃ¡ticamente
   - BCE loss con ponderaciÃ³n por posiciÃ³n

2. **Data Augmentation**:
   - AumentaciÃ³n especÃ­fica para textos mÃ©dicos
   - GeneraciÃ³n de muestras sintÃ©ticas para combinaciones raras

3. **ConfiguraciÃ³n de entrenamiento**:
   - Learning rate: 2e-5
   - Batch size efectivo: 24 (6 Ã— 4 gradient accumulation)
   - Ã‰pocas: 4
   - RegularizaciÃ³n: Weight decay 0.1, Label smoothing 0.05

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

El modelo utiliza mÃºltiples mÃ©tricas para evaluaciÃ³n:

- **F1 Macro**: Promedio no ponderado de F1 por clase
- **F1 Micro**: F1 global considerando todas las predicciones
- **F1 Weighted**: F1 ponderado por frecuencia de clase
- **Subset Accuracy**: Exactitud de predicciÃ³n completa
- **Hamming Loss**: PÃ©rdida promedio por etiqueta

### MÃ©tricas por categorÃ­a individual
- PrecisiÃ³n, Recall y F1-Score para cada categorÃ­a mÃ©dica

## ğŸ” AnÃ¡lisis de Datos

### Notebooks disponibles

1. **DataAnalysis.ipynb**:
   - AnÃ¡lisis exploratorio completo
   - Visualizaciones de distribuciÃ³n
   - WordClouds por categorÃ­a
   - AnÃ¡lisis de longitud de texto

2. **last_final.ipynb**:
   - Pipeline completo de entrenamiento
   - ExperimentaciÃ³n con hiperparÃ¡metros
   - Funciones de prueba y predicciÃ³n

## âš¡ CaracterÃ­sticas Avanzadas

### Data Augmentation Inteligente
- SinÃ³nimos mÃ©dicos especÃ­ficos
- Patrones de co-ocurrencia
- Templates para combinaciones raras

### Manejo de Multi-etiquetas
- EstratificaciÃ³n preservando distribuciÃ³n multi-etiqueta
- MÃ©tricas especializadas para clasificaciÃ³n multi-etiqueta
- AnÃ¡lisis de patrones de co-ocurrencia

### Monitoreo y Logging
- IntegraciÃ³n con Weights & Biases (wandb)
- Seguimiento detallado de mÃ©tricas
- VisualizaciÃ³n de progreso en tiempo real

## ğŸ›ï¸ ConfiguraciÃ³n Avanzada

### HiperparÃ¡metros principales
```python
TrainingArguments(
    num_train_epochs=4,
    per_device_train_batch_size=6,
    gradient_accumulation_steps=4,
    learning_rate=2e-5,
    weight_decay=0.1,
    warmup_ratio=0.1,
    lr_scheduler_type="cosine_with_restarts",
    label_smoothing_factor=0.05
)
```

### Threshold de predicciÃ³n
- Por defecto: 0.5
- Ajustable segÃºn necesidades del dominio
- Optimizable mediante validaciÃ³n cruzada

## ğŸ“‹ Resultados Esperados

El modelo estÃ¡ optimizado para:
- **Casos multi-etiqueta**: IdentificaciÃ³n precisa de documentos con mÃºltiples categorÃ­as
- **CategorÃ­as raras**: Manejo especial de combinaciones poco frecuentes
- **Interpretabilidad**: Probabilidades de confianza para cada categorÃ­a

## ğŸ¤ ContribuciÃ³n

Para contribuir al proyecto:
1. Fork del repositorio
2. Crear rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia [especificar licencia].

## ğŸ”¬ Casos de Uso

### Ejemplos de aplicaciÃ³n
- **ClasificaciÃ³n automÃ¡tica** de literatura mÃ©dica
- **IndexaciÃ³n** de bases de datos mÃ©dicas
- **Filtrado inteligente** por especialidad mÃ©dica
- **AnÃ¡lisis de tendencias** en investigaciÃ³n mÃ©dica

### Ejemplo de predicciÃ³n
```python
texto = "Doxorubicin cardiotoxicity in cancer patients with renal dysfunction"
# Resultado esperado: cardiovascular + hepatorenal + oncological
```

## ğŸ“ Contacto

Para preguntas o soporte, contactar a [informaciÃ³n de contacto].

---

*Proyecto desarrollado para la clasificaciÃ³n automÃ¡tica de textos mÃ©dicos usando tÃ©cnicas de deep learning y NLP especializado.*