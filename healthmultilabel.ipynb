{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Qj6zZ9K9R_wk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    default_data_collator\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, hamming_loss, precision_score, recall_score\n",
        "from torch.utils.data import Dataset\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_gpu():\n",
        "    \"\"\"Check GPU availability\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    else:\n",
        "        print(\"WARNING: No GPU available\")\n",
        "\n",
        "def load_model_and_tokenizer():\n",
        "    \"\"\"Load PubMedBERT model and tokenizer\"\"\"\n",
        "    model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=4,\n",
        "        problem_type=\"multi_label_classification\"\n",
        "    )\n",
        "\n",
        "    print(f\"Model loaded: {model.num_parameters():,} parameters\")\n",
        "    return tokenizer, model"
      ],
      "metadata": {
        "id": "X0DbUjlWSJCR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_medical_dataset(df):\n",
        "    \"\"\"Convert multi-label medical dataset to binary format\"\"\"\n",
        "    category_mapping = {\n",
        "        'neurological': 0,\n",
        "        'cardiovascular': 1,\n",
        "        'hepatorenal': 2,\n",
        "        'oncological': 3\n",
        "    }\n",
        "\n",
        "    def parse_medical_labels(group_str):\n",
        "        labels = [0, 0, 0, 0]\n",
        "        if pd.isna(group_str):\n",
        "            return labels\n",
        "\n",
        "        categories = str(group_str).split('|')\n",
        "        for cat in categories:\n",
        "            cat = cat.strip().lower()\n",
        "            if cat in category_mapping:\n",
        "                labels[category_mapping[cat]] = 1\n",
        "        return labels\n",
        "\n",
        "    # Create combined text\n",
        "    df['text'] = df['title'].astype(str) + \" [SEP] \" + df['abstract'].astype(str)\n",
        "\n",
        "    # Convert labels\n",
        "    df['labels'] = df['group'].apply(parse_medical_labels)\n",
        "\n",
        "    # Print distribution\n",
        "    categories = ['neurological', 'cardiovascular', 'hepatorenal', 'oncological']\n",
        "    print(\"\\nLabel distribution:\")\n",
        "    for i, cat in enumerate(categories):\n",
        "        count = sum(1 for labels in df['labels'] if labels[i] == 1)\n",
        "        percentage = (count / len(df)) * 100\n",
        "        print(f\"  {cat:15}: {count:4d} samples ({percentage:5.1f}%)\")\n",
        "\n",
        "    return df[['text', 'labels']].copy()\n",
        "\n",
        "def analyze_text_lengths(df, tokenizer):\n",
        "    \"\"\"Analyze text lengths for optimal max_length\"\"\"\n",
        "    lengths = df['text'].apply(lambda x: len(tokenizer.encode(str(x))))\n",
        "\n",
        "    print(f\"\\nText length analysis:\")\n",
        "    print(f\"  Mean: {lengths.mean():.0f} tokens\")\n",
        "    print(f\"  95th percentile: {lengths.quantile(0.95):.0f} tokens\")\n",
        "    print(f\"  Max: {lengths.max():.0f} tokens\")\n",
        "\n",
        "    optimal_length = min(512, int(lengths.quantile(0.95)))\n",
        "    print(f\"  Recommended max_length: {optimal_length}\")\n",
        "\n",
        "    return optimal_length"
      ],
      "metadata": {
        "id": "KEK-BTfHSLGo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalPapersDataset(Dataset):\n",
        "    \"\"\"Custom dataset ensuring correct data types for multi-label classification\"\"\"\n",
        "\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts.reset_index(drop=True)\n",
        "        self.labels = labels.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts.iloc[idx])\n",
        "        labels = self.labels.iloc[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(labels, dtype=torch.float32)\n",
        "        }"
      ],
      "metadata": {
        "id": "ZeQOuKqhSNie"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_multilabel_metrics(eval_pred):\n",
        "    \"\"\"Compute comprehensive multi-label metrics\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Apply sigmoid and threshold\n",
        "    predictions = torch.sigmoid(torch.tensor(predictions))\n",
        "    predictions = (predictions > 0.5).int().numpy()\n",
        "\n",
        "    # Global metrics\n",
        "    metrics = {\n",
        "        'f1_macro': f1_score(labels, predictions, average='macro', zero_division=0),\n",
        "        'f1_micro': f1_score(labels, predictions, average='micro', zero_division=0),\n",
        "        'f1_weighted': f1_score(labels, predictions, average='weighted', zero_division=0),\n",
        "        'subset_accuracy': accuracy_score(labels, predictions),\n",
        "        'hamming_loss': hamming_loss(labels, predictions)\n",
        "    }\n",
        "\n",
        "    # Per-category metrics\n",
        "    categories = ['neurological', 'cardiovascular', 'hepatorenal', 'oncological']\n",
        "    for i, cat in enumerate(categories):\n",
        "        cat_labels = labels[:, i]\n",
        "        cat_preds = predictions[:, i]\n",
        "\n",
        "        metrics[f'f1_{cat}'] = f1_score(cat_labels, cat_preds, zero_division=0)\n",
        "        metrics[f'precision_{cat}'] = precision_score(cat_labels, cat_preds, zero_division=0)\n",
        "        metrics[f'recall_{cat}'] = recall_score(cat_labels, cat_preds, zero_division=0)\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "wicZQ3WVSPQE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_args():\n",
        "    \"\"\"Configure training arguments optimized for T4 GPU\"\"\"\n",
        "    return TrainingArguments(\n",
        "        output_dir='./pubmedbert-medical-results',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=2,\n",
        "        gradient_accumulation_steps=3,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=50,\n",
        "        logging_steps=25,\n",
        "        fp16=True,\n",
        "        learning_rate=2e-5,\n",
        "        warmup_steps=100,\n",
        "        weight_decay=0.05,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=150,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "        seed=42,\n",
        "        report_to=None  # Disable wandb\n",
        "    )\n"
      ],
      "metadata": {
        "id": "wZoB8S0oSSGs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_medical_classifier(csv_path, sep=\";\", quotechar='\"'):\n",
        "    \"\"\"Complete training pipeline\"\"\"\n",
        "\n",
        "    # Setup\n",
        "    print(\"=== Medical Paper Classification Training ===\")\n",
        "    check_gpu()\n",
        "\n",
        "    # Load data\n",
        "    print(f\"\\nLoading data from {csv_path}\")\n",
        "    df = pd.read_csv(csv_path, sep=sep, quotechar=quotechar, quoting=1)\n",
        "    print(f\"Loaded {len(df):,} samples\")\n",
        "\n",
        "    # Load model\n",
        "    print(\"\\nLoading PubMedBERT model...\")\n",
        "    tokenizer, model = load_model_and_tokenizer()\n",
        "\n",
        "    # Prepare data\n",
        "    print(\"\\nPreparing dataset...\")\n",
        "    df_prepared = prepare_medical_dataset(df)\n",
        "\n",
        "    # Analyze text lengths\n",
        "    optimal_max_length = analyze_text_lengths(df_prepared, tokenizer)\n",
        "\n",
        "    # Train/validation split\n",
        "    print(\"\\nSplitting data...\")\n",
        "    df_prepared['label_string'] = df_prepared['labels'].apply(str)\n",
        "    train_df, val_df = train_test_split(\n",
        "        df_prepared,\n",
        "        test_size=0.2,\n",
        "        stratify=df_prepared['label_string'],\n",
        "        random_state=42\n",
        "    )\n",
        "    print(f\"Train: {len(train_df):,}, Validation: {len(val_df):,}\")\n",
        "\n",
        "    # Create datasets\n",
        "    print(\"\\nCreating datasets...\")\n",
        "    train_dataset = MedicalPapersDataset(\n",
        "        train_df['text'], train_df['labels'], tokenizer, optimal_max_length\n",
        "    )\n",
        "    val_dataset = MedicalPapersDataset(\n",
        "        val_df['text'], val_df['labels'], tokenizer, optimal_max_length\n",
        "    )\n",
        "\n",
        "    # Verify data types\n",
        "    sample = train_dataset[0]\n",
        "    assert sample['labels'].dtype == torch.float32, \"Labels must be float32\"\n",
        "    print(\"Data types verified successfully\")\n",
        "\n",
        "    # Setup training\n",
        "    training_args = get_training_args()\n",
        "    data_collator = default_data_collator\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_multilabel_metrics,\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    print(f\"\\nStarting training...\")\n",
        "    print(f\"Training parameters:\")\n",
        "    print(f\"  - Epochs: {training_args.num_train_epochs}\")\n",
        "    print(f\"  - Batch size (effective): {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
        "    print(f\"  - Learning rate: {training_args.learning_rate}\")\n",
        "    print(f\"  - Max sequence length: {optimal_max_length}\")\n",
        "\n",
        "    train_result = trainer.train()\n",
        "\n",
        "    # Final evaluation\n",
        "    print(\"\\nFinal evaluation...\")\n",
        "    final_metrics = trainer.evaluate()\n",
        "\n",
        "    # Print key results\n",
        "    print(\"\\nTraining completed! Key metrics:\")\n",
        "    key_metrics = ['eval_f1_macro', 'eval_f1_micro', 'eval_subset_accuracy', 'eval_hamming_loss']\n",
        "    for metric in key_metrics:\n",
        "        if metric in final_metrics:\n",
        "            print(f\"  {metric.replace('eval_', '')}: {final_metrics[metric]:.4f}\")\n",
        "\n",
        "    print(\"\\nPer-category F1 scores:\")\n",
        "    categories = ['neurological', 'cardiovascular', 'hepatorenal', 'oncological']\n",
        "    for cat in categories:\n",
        "        f1_key = f'eval_f1_{cat}'\n",
        "        if f1_key in final_metrics:\n",
        "            print(f\"  {cat}: {final_metrics[f1_key]:.4f}\")\n",
        "\n",
        "    # Save model\n",
        "    model_path = \"./pubmedbert-medical-final\"\n",
        "    trainer.save_model(model_path)\n",
        "    tokenizer.save_pretrained(model_path)\n",
        "    print(f\"\\nModel saved to: {model_path}\")\n",
        "\n",
        "    return trainer, final_metrics"
      ],
      "metadata": {
        "id": "RVo86V4uSSlo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_medical_categories(text, model_path=\"./pubmedbert-medical-final\", threshold=0.5):\n",
        "    \"\"\"Predict medical categories for new text\"\"\"\n",
        "    categories = ['neurological', 'cardiovascular', 'hepatorenal', 'oncological']\n",
        "\n",
        "    # Load model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.sigmoid(outputs.logits)[0]\n",
        "\n",
        "    # Format results\n",
        "    results = []\n",
        "    for i, (category, prob) in enumerate(zip(categories, predictions)):\n",
        "        results.append({\n",
        "            'category': category,\n",
        "            'probability': prob.item(),\n",
        "            'predicted': prob.item() > threshold\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "viX5QiX0SW6t"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Train the model\n",
        "    csv_file = \"/content/challenge_data-18-ago.csv\"  # Update path as needed\n",
        "    trainer, metrics = train_medical_classifier(csv_file)\n",
        "\n",
        "    # Example prediction\n",
        "    sample_text = \"\"\"\n",
        "    Alzheimer disease treatment shows significant improvement in cognitive function.\n",
        "    This study demonstrates the effectiveness of new therapeutic approaches\n",
        "    for neurodegenerative conditions affecting memory and cognition.\n",
        "    \"\"\"\n",
        "\n",
        "    predictions = predict_medical_categories(sample_text)\n",
        "\n",
        "    print(\"\\nExample prediction:\")\n",
        "    for pred in predictions:\n",
        "        if pred['predicted']:\n",
        "            print(f\"  {pred['category']}: {pred['probability']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JQVc-gfDSXZ4",
        "outputId": "5a171e3b-3e5e-4723-f39e-76919346c409"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Medical Paper Classification Training ===\n",
            "GPU: Tesla T4\n",
            "VRAM: 14.7 GB\n",
            "\n",
            "Loading data from /content/challenge_data-18-ago.csv\n",
            "Loaded 3,565 samples\n",
            "\n",
            "Loading PubMedBERT model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded: 109,485,316 parameters\n",
            "\n",
            "Preparing dataset...\n",
            "\n",
            "Label distribution:\n",
            "  neurological   : 1785 samples ( 50.1%)\n",
            "  cardiovascular : 1268 samples ( 35.6%)\n",
            "  hepatorenal    : 1091 samples ( 30.6%)\n",
            "  oncological    :  601 samples ( 16.9%)\n",
            "\n",
            "Text length analysis:\n",
            "  Mean: 145 tokens\n",
            "  95th percentile: 397 tokens\n",
            "  Max: 723 tokens\n",
            "  Recommended max_length: 397\n",
            "\n",
            "Splitting data...\n",
            "Train: 2,852, Validation: 713\n",
            "\n",
            "Creating datasets...\n",
            "Data types verified successfully\n",
            "\n",
            "Starting training...\n",
            "Training parameters:\n",
            "  - Epochs: 3\n",
            "  - Batch size (effective): 24\n",
            "  - Learning rate: 2e-05\n",
            "  - Max sequence length: 397\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='357' max='357' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [357/357 04:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Subset Accuracy</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>F1 Neurological</th>\n",
              "      <th>Precision Neurological</th>\n",
              "      <th>Recall Neurological</th>\n",
              "      <th>F1 Cardiovascular</th>\n",
              "      <th>Precision Cardiovascular</th>\n",
              "      <th>Recall Cardiovascular</th>\n",
              "      <th>F1 Hepatorenal</th>\n",
              "      <th>Precision Hepatorenal</th>\n",
              "      <th>Recall Hepatorenal</th>\n",
              "      <th>F1 Oncological</th>\n",
              "      <th>Precision Oncological</th>\n",
              "      <th>Recall Oncological</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.606500</td>\n",
              "      <td>0.592264</td>\n",
              "      <td>0.166826</td>\n",
              "      <td>0.426829</td>\n",
              "      <td>0.251733</td>\n",
              "      <td>0.288920</td>\n",
              "      <td>0.329593</td>\n",
              "      <td>0.667302</td>\n",
              "      <td>0.506512</td>\n",
              "      <td>0.977654</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.316100</td>\n",
              "      <td>112.887000</td>\n",
              "      <td>56.522000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.532800</td>\n",
              "      <td>0.410063</td>\n",
              "      <td>0.612242</td>\n",
              "      <td>0.759509</td>\n",
              "      <td>0.715909</td>\n",
              "      <td>0.575035</td>\n",
              "      <td>0.137447</td>\n",
              "      <td>0.859135</td>\n",
              "      <td>0.857939</td>\n",
              "      <td>0.860335</td>\n",
              "      <td>0.811189</td>\n",
              "      <td>0.994286</td>\n",
              "      <td>0.685039</td>\n",
              "      <td>0.745856</td>\n",
              "      <td>0.931034</td>\n",
              "      <td>0.622120</td>\n",
              "      <td>0.032787</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>9.190200</td>\n",
              "      <td>77.583000</td>\n",
              "      <td>38.846000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.243200</td>\n",
              "      <td>0.209004</td>\n",
              "      <td>0.904164</td>\n",
              "      <td>0.901235</td>\n",
              "      <td>0.901166</td>\n",
              "      <td>0.775596</td>\n",
              "      <td>0.061711</td>\n",
              "      <td>0.880240</td>\n",
              "      <td>0.948387</td>\n",
              "      <td>0.821229</td>\n",
              "      <td>0.918919</td>\n",
              "      <td>0.973568</td>\n",
              "      <td>0.870079</td>\n",
              "      <td>0.913151</td>\n",
              "      <td>0.989247</td>\n",
              "      <td>0.847926</td>\n",
              "      <td>0.904348</td>\n",
              "      <td>0.945455</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>6.323400</td>\n",
              "      <td>112.756000</td>\n",
              "      <td>56.457000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.197400</td>\n",
              "      <td>0.185121</td>\n",
              "      <td>0.910882</td>\n",
              "      <td>0.910186</td>\n",
              "      <td>0.910331</td>\n",
              "      <td>0.789621</td>\n",
              "      <td>0.057504</td>\n",
              "      <td>0.904965</td>\n",
              "      <td>0.919308</td>\n",
              "      <td>0.891061</td>\n",
              "      <td>0.910603</td>\n",
              "      <td>0.964758</td>\n",
              "      <td>0.862205</td>\n",
              "      <td>0.920398</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.852535</td>\n",
              "      <td>0.907563</td>\n",
              "      <td>0.915254</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>9.367200</td>\n",
              "      <td>76.117000</td>\n",
              "      <td>38.112000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.159500</td>\n",
              "      <td>0.160017</td>\n",
              "      <td>0.929904</td>\n",
              "      <td>0.930131</td>\n",
              "      <td>0.929958</td>\n",
              "      <td>0.837307</td>\n",
              "      <td>0.044881</td>\n",
              "      <td>0.911208</td>\n",
              "      <td>0.951368</td>\n",
              "      <td>0.874302</td>\n",
              "      <td>0.943775</td>\n",
              "      <td>0.963115</td>\n",
              "      <td>0.925197</td>\n",
              "      <td>0.957143</td>\n",
              "      <td>0.990148</td>\n",
              "      <td>0.926267</td>\n",
              "      <td>0.907489</td>\n",
              "      <td>0.962617</td>\n",
              "      <td>0.858333</td>\n",
              "      <td>6.193400</td>\n",
              "      <td>115.123000</td>\n",
              "      <td>57.642000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.159300</td>\n",
              "      <td>0.153291</td>\n",
              "      <td>0.934353</td>\n",
              "      <td>0.932176</td>\n",
              "      <td>0.931755</td>\n",
              "      <td>0.845722</td>\n",
              "      <td>0.043829</td>\n",
              "      <td>0.907216</td>\n",
              "      <td>0.959502</td>\n",
              "      <td>0.860335</td>\n",
              "      <td>0.950298</td>\n",
              "      <td>0.959839</td>\n",
              "      <td>0.940945</td>\n",
              "      <td>0.953488</td>\n",
              "      <td>0.962441</td>\n",
              "      <td>0.944700</td>\n",
              "      <td>0.926407</td>\n",
              "      <td>0.963964</td>\n",
              "      <td>0.891667</td>\n",
              "      <td>6.769700</td>\n",
              "      <td>105.322000</td>\n",
              "      <td>52.735000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.132400</td>\n",
              "      <td>0.148037</td>\n",
              "      <td>0.934763</td>\n",
              "      <td>0.933261</td>\n",
              "      <td>0.932999</td>\n",
              "      <td>0.844320</td>\n",
              "      <td>0.043128</td>\n",
              "      <td>0.913616</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.871508</td>\n",
              "      <td>0.948207</td>\n",
              "      <td>0.959677</td>\n",
              "      <td>0.937008</td>\n",
              "      <td>0.950820</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>0.935484</td>\n",
              "      <td>0.926407</td>\n",
              "      <td>0.963964</td>\n",
              "      <td>0.891667</td>\n",
              "      <td>6.842100</td>\n",
              "      <td>104.207000</td>\n",
              "      <td>52.177000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final evaluation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='357' max='357' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [357/357 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training completed! Key metrics:\n",
            "  f1_macro: 0.9344\n",
            "  f1_micro: 0.9322\n",
            "  subset_accuracy: 0.8457\n",
            "  hamming_loss: 0.0438\n",
            "\n",
            "Per-category F1 scores:\n",
            "  neurological: 0.9072\n",
            "  cardiovascular: 0.9503\n",
            "  hepatorenal: 0.9535\n",
            "  oncological: 0.9264\n",
            "\n",
            "Model saved to: ./pubmedbert-medical-final\n",
            "\n",
            "Example prediction:\n",
            "  neurological: 0.978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_path = \"./pubmedbert-medical-final\"\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    print(\"Model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMSDFF5AfK1S",
        "outputId": "d2a549b2-3a49-4eea-fac3-246646112fa9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_medical_categories(text, model_path=\"./pubmedbert-medical-final\", threshold=0.5):\n",
        "    categories = ['neurological', 'cardiovascular', 'hepatorenal', 'oncological']\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=397  # Same as training\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.sigmoid(outputs.logits)[0]\n",
        "\n",
        "    results = []\n",
        "    for i, (category, prob) in enumerate(zip(categories, predictions)):\n",
        "        results.append({\n",
        "            'category': category,\n",
        "            'probability': prob.item(),\n",
        "            'predicted': prob.item() > threshold\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test it\n",
        "sample_text = \"endoscopy reveals ventricular tachycardia secrets Research question: How does metformin affect cancer through pituitary adenoma mechanisms? Methods: randomized controlled study with 53 elderly patients, assessing encephalitis and aphasia. Results: significant improvement in primary endpoints. Implications: therapeutic innovation.\"\n",
        "\n",
        "\n",
        "predictions = predict_medical_categories(sample_text)\n",
        "\n",
        "for pred in predictions:\n",
        "    if pred['predicted']:\n",
        "        print(f\"{pred['category']}: {pred['probability']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzSk0cRUfYy4",
        "outputId": "7dcfbc07-b76b-469d-9ad1-e97491d5e314"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neurological: 0.985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/challenge_data-18-ago.csv\", sep=';', quotechar='\"', quoting=1)"
      ],
      "metadata": {
        "id": "Dds1B0MXhndS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prepared = prepare_medical_dataset(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSYBTTEMhiFS",
        "outputId": "2bb062b1-7479-49e2-e23f-367381814ce7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label distribution:\n",
            "  neurological   : 1785 samples ( 50.1%)\n",
            "  cardiovascular : 1268 samples ( 35.6%)\n",
            "  hepatorenal    : 1091 samples ( 30.6%)\n",
            "  oncological    :  601 samples ( 16.9%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_prepared.loc[3525]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "b_bcNurLh_6L",
        "outputId": "7f617165-ed2b-4041-ec0e-1a74e5d9baa8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      Carvedilol protects against doxorubicin-induce...\n",
              "labels                                         [1, 1, 1, 1]\n",
              "Name: 3525, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3525</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>Carvedilol protects against doxorubicin-induce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels</th>\n",
              "      <td>[1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}